{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMvjzEUr62fp",
        "outputId": "6dcb215f-bdaf-4faf-a4a1-569548ca8b6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lowercased Text:\n",
            "\n",
            "an information retrieval system (irs) is a software-based framework: it collects, organizes,\n",
            "and retrieves information from repositories—e.g., databases, documents, or websites!\n",
            "can it help with efficient data access? absolutely!\n",
            "\n",
            "\n",
            "Cleaned Text without Punctuation:\n",
            "\n",
            "an information retrieval system irs is a softwarebased framework it collects organizes\n",
            "and retrieves information from repositories—eg databases documents or websites\n",
            "can it help with efficient data access absolutely\n",
            "\n",
            "\n",
            "Tokenized Sentences:\n",
            "['\\nan information retrieval system irs is a softwarebased framework it collects organizes\\nand retrieves information from repositories—eg databases documents or websites\\ncan it help with efficient data access absolutely']\n",
            "\n",
            "Tokenized Words:\n",
            "['an', 'information', 'retrieval', 'system', 'ir', 'is', 'a', 'softwarebased', 'framework', 'it', 'collects', 'organizes', 'and', 'retrieves', 'information', 'from', 'repositories—eg', 'databases', 'documents', 'or', 'websites', 'can', 'it', 'help', 'with', 'efficient', 'data', 'access', 'absolutely']\n",
            "\n",
            "Words after Removing Stopwords:\n",
            "['information', 'retrieval', 'system', 'ir', 'softwarebased', 'framework', 'collects', 'organizes', 'retrieves', 'information', 'repositories—eg', 'databases', 'documents', 'websites', 'help', 'efficient', 'data', 'access', 'absolutely']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "\n",
        "text = \"\"\"\n",
        "An Information Retrieval System (IRS) is a software-based framework: it collects, organizes,\n",
        "and retrieves information from repositories—e.g., databases, documents, or websites!\n",
        "Can it help with efficient data access? Absolutely!\n",
        "\"\"\"\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "lowercased_text = text.lower()\n",
        "cleaned_text = lowercased_text.translate(str.maketrans('', '', string.punctuation))\n",
        "sentences = sent_tokenize(cleaned_text)\n",
        "stop_words = set(stopwords.words('english'))\n",
        "filtered_words = [word for word in words if word not in stop_words]\n",
        "print(\"Lowercased Text:\")\n",
        "print(lowercased_text)\n",
        "print(\"\\nCleaned Text without Punctuation:\")\n",
        "print(cleaned_text)\n",
        "print(\"\\nTokenized Sentences:\")\n",
        "print(sentences)\n",
        "print(\"\\nTokenized Words:\")\n",
        "print(words)\n",
        "print(\"\\nWords after Removing Stopwords:\")\n",
        "print(filtered_words)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://colab.research.google.com/drive/1HGoyslsBv5zJ9scf_LprLFzUlxywWtdm?usp=sharing\n"
      ],
      "metadata": {
        "id": "Afh49iF8NH6W"
      }
    }
  ]
}